"""
DP utilities for differential privacy.
"""
import numpy as np
import jax
import jax.numpy as jnp
from jax import random

def compute_dp_sgd_privacy(n, batch_size, target_epsilon, target_delta, epochs):
    """
    Compute noise multiplier for DP-SGD.
    Based on the moments accountant.
    
    Returns:
        noise_multiplier: The σ parameter for Gaussian noise
    """
    # Simplified calculation - in practice, use a proper DP accountant
    if target_epsilon <= 0 or target_delta <= 0:
        return 0.0
    
    q = batch_size / n  # Sampling probability
    steps = epochs * n // batch_size
    
    # Use the Gaussian mechanism formula: σ = Δf * sqrt(2 * ln(1.25/δ)) / ε
    # Where Δf is sensitivity (we use clip_norm=1.0)
    clip_norm = 1.0
    noise_multiplier = clip_norm * np.sqrt(2 * np.log(1.25 / target_delta)) / target_epsilon
    
    # Adjust for composition: σ_total = σ / sqrt(steps)
    # This is a simplification - proper accounting would use moments accountant
    if steps > 1:
        noise_multiplier = noise_multiplier / np.sqrt(steps)
    
    return float(max(noise_multiplier, 0.1))  # Ensure minimum noise

def add_noise_to_grads(grads, epsilon, delta, clip_norm=1.0):
    """
    Add calibrated Gaussian noise to gradients for DP-SGD.
    
    Args:
        grads: Gradient tree
        epsilon: Privacy budget per step
        delta: Privacy parameter
        clip_norm: Gradient clipping norm
    
    Returns:
        Noisy gradients
    """
    if epsilon <= 0 or delta <= 0:
        return grads
    
    # Clip gradients to bound sensitivity
    def clip_gradient(g):
        norm = jnp.linalg.norm(g)
        scale = jnp.minimum(1.0, clip_norm / (norm + 1e-10))
        return g * scale
    
    grads = jax.tree_map(clip_gradient, grads)
    
    # Compute noise scale: σ = clip_norm * sqrt(2 * log(1.25/δ)) / ε
    noise_scale = clip_norm * np.sqrt(2 * np.log(1.25 / delta)) / epsilon
    
    # Add Gaussian noise to each gradient
    key = random.PRNGKey(0)
    
    def add_noise(g):
        # Generate new key for each operation
        key, subkey = random.split(key)
        noise = noise_scale * random.normal(subkey, g.shape)
        return g + noise
    
    # Apply noise to all gradients
    noisy_grads = jax.tree_map(add_noise, grads)
    
    return noisy_grads

def compute_renyi_dp(q, sigma, steps, alpha):
    """
    Compute Renyi Differential Privacy.
    
    Args:
        q: Sampling probability (batch_size / n)
        sigma: Noise multiplier
        steps: Number of steps
        alpha: Renyi order
    
    Returns:
        Renyi divergence (ε_α)
    """
    # Placeholder - in practice use Opacus or TensorFlow Privacy libraries
    return alpha / (2 * sigma ** 2) if sigma > 0 else float('inf')

class PrivacyAccountant:
    """Track privacy spending using moments accountant."""
    
    def __init__(self, target_delta=1e-5):
        self.target_delta = target_delta
        self.rdp_alphas = list(range(2, 65))
        self.rdp_budget = {alpha: 0.0 for alpha in self.rdp_alphas}
    
    def add_step(self, q, sigma):
        """Add one DP-SGD step to the accountant."""
        for alpha in self.rdp_alphas:
            # RDP for Gaussian mechanism with sampling
            rdp_alpha = self._compute_rdp_gaussian(q, sigma, alpha)
            self.rdp_budget[alpha] += rdp_alpha
    
    def get_epsilon(self, delta=None):
        """Convert RDP to (ε, δ)-DP."""
        if delta is None:
            delta = self.target_delta
        
        eps = float('inf')
        for alpha, rdp in self.rdp_budget.items():
            eps = min(eps, rdp + np.log(1/delta)/(alpha-1))
        
        return eps
    
    def _compute_rdp_gaussian(self, q, sigma, alpha):
        """Compute RDP for Gaussian mechanism with Poisson sampling."""
        if sigma == 0:
            return float('inf')
        
        # Simplified approximation
        return alpha / (2 * sigma ** 2)
